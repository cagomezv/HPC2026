# ‚öôÔ∏è Sistemas Distribuidos (Computaci√≥n de Alto Desempe√±o para F√≠sica)

**Facultad:** Facultad de Ciencias Matem√°ticas y Naturales  
**Proyecto Curricular:** F√≠sica  
**Tipo de asignatura:** Te√≥rico‚ÄìPr√°ctica  
**Modalidad:** Presencial con incorporaci√≥n de TIC  
**Cr√©ditos acad√©micos:** 3  

**Distribuci√≥n horaria:**
- HTD: 4
- HTC: 2
- HTA: 3

---

## üìå Descripci√≥n del curso
El curso **Sistemas Distribuidos** introduce los fundamentos y t√©cnicas de la **Computaci√≥n de Alto Desempe√±o (HPC)** aplicadas a la resoluci√≥n de problemas complejos en f√≠sica. Se enfoca en el dise√±o, implementaci√≥n y optimizaci√≥n de algoritmos paralelos y distribuidos, permitiendo a los estudiantes acelerar simulaciones num√©ricas y manejar grandes vol√∫menes de datos cient√≠ficos.

A lo largo del curso se abordan arquitecturas de memoria compartida y distribuida, optimizaci√≥n de c√≥digo, √°lgebra lineal dispersa y programaci√≥n paralela con **OpenMP** y **MPI**, integrando estos conceptos en aplicaciones reales de la f√≠sica computacional.

---

## üß≠ Justificaci√≥n
La f√≠sica contempor√°nea depende fuertemente de simulaciones num√©ricas intensivas y del procesamiento eficiente de grandes cantidades de datos. En √°reas como din√°mica de fluidos, f√≠sica de materiales, astrof√≠sica, biof√≠sica y f√≠sica estad√≠stica, muchos problemas son computacionalmente intratables sin el uso de plataformas paralelas y distribuidas.

Este curso proporciona a los estudiantes las competencias necesarias para implementar algoritmos eficientes en arquitecturas modernas de c√≥mputo, optimizar el uso de memoria y recursos computacionales, y reducir significativamente los tiempos de ejecuci√≥n de simulaciones f√≠sicas. Adem√°s, fortalece habilidades clave para la investigaci√≥n cient√≠fica, la industria tecnol√≥gica y campos emergentes como la inteligencia artificial y la computaci√≥n cu√°ntica.

El enfoque en trabajo colaborativo, optimizaci√≥n de rendimiento y comunicaci√≥n de resultados cient√≠ficos prepara a los estudiantes para participar activamente en proyectos de investigaci√≥n y desarrollo que requieren un dominio profundo de la computaci√≥n cient√≠fica moderna.

---

## üéØ Objetivos del curso

### Objetivo general
Desarrollar en los estudiantes habilidades para la implementaci√≥n, optimizaci√≥n y aplicaci√≥n de m√©todos de **computaci√≥n de alto desempe√±o (HPC)** en la resoluci√≥n de problemas complejos de f√≠sica, integrando programaci√≥n paralela, estructuras de datos dispersas y algoritmos eficientes.

### Objetivos espec√≠ficos
- Comprender y aplicar principios fundamentales de HPC para la optimizaci√≥n de c√≥digo y el manejo eficiente de memoria.
- Desarrollar simulaciones num√©ricas en entornos de c√≥mputo paralelo utilizando **OpenMP** y **MPI**.
- Implementar y analizar algoritmos de √°lgebra lineal dispersa para problemas f√≠sicos de gran escala.
- Analizar y comunicar resultados de simulaciones mediante reportes t√©cnicos y visualizaci√≥n de datos.

---

## üéì Prop√≥sitos de Formaci√≥n y Aprendizaje (PFA)
Al finalizar el curso, el estudiante ser√° capaz de:

1. Implementar y optimizar algoritmos de alto desempe√±o para la simulaci√≥n de fen√≥menos f√≠sicos complejos.
2. Dise√±ar y ejecutar experimentos computacionales en entornos de HPC, validando resultados con metodolog√≠as rigurosas.
3. Desarrollar habilidades de autoformaci√≥n y actualizaci√≥n en computaci√≥n cient√≠fica avanzada.
4. Participar en proyectos de investigaci√≥n y desarrollo que involucren c√≥mputo distribuido y manejo de grandes vol√∫menes de datos.
5. Comunicar de manera efectiva procesos y resultados de simulaciones mediante reportes t√©cnicos y visualizaciones cient√≠ficas.

---

## üìé Requisitos y conocimientos previos
- Programaci√≥n en C/C++ o Python
- √Ålgebra lineal
- M√©todos num√©ricos b√°sicos
- F√≠sica computacional (recomendado)

---

## üõ†Ô∏è Herramientas y entorno de trabajo
- **Lenguajes:** C, C++, Python
- **Compiladores:** GCC, Clang
- **Paralelismo:** OpenMP, MPI (MPICH u OpenMPI)
- **Librer√≠as cient√≠ficas:** BLAS, LAPACK
- **Optimizaci√≥n y depuraci√≥n:** Valgrind, GDB, Perf
- **Herramientas adicionales:** METIS, Make, CMake, Git
- **Entorno:** Linux (preferiblemente Debian) y Windows
- **Opcional:** Slurm, Docker

---

## üìö Contenidos tem√°ticos

### üü¢ Semana 1: Introducci√≥n a HPC
- Motivaci√≥n y aplicaciones de HPC en f√≠sica.
- Arquitecturas paralelas.
- Memoria compartida vs. distribuida.
- Clusters y supercomputadoras.

### üü° Semanas 2‚Äì4: Optimizaci√≥n de c√≥digo
- Arquitectura de procesadores modernos.
- Uso eficiente de cach√© y memoria.
- Directivas de compilaci√≥n.
- Debug vs. release.
- Sobrecarga de operadores y costos computacionales.

### üîµ Semanas 5‚Äì6: √Ålgebra lineal y matrices dispersas
- Matrices ralas y formatos CRS/CCS.
- Sistemas de ecuaciones dispersos.
- Gradiente conjugado.
- Precondicionamiento y estabilidad num√©rica.

### üü£ Semanas 7‚Äì9: Paralelismo con OpenMP
- Programaci√≥n con threads.
- Paralelizaci√≥n de bucles.
- Reducciones y secciones cr√≠ticas.
- Speed-up y ley de Amdahl.
- NUMA y false-sharing.

### üü† Semanas 10‚Äì12: Factorizaci√≥n y precondicionamiento
- Cholesky simb√≥lica y num√©rica.
- Reordenamientos con METIS.
- Factorizaciones incompletas.
- M√©todos biconjugados y precondicionadores avanzados.

### üî¥ Semanas 13‚Äì15: Paralelismo con MPI
- Programaci√≥n en memoria distribuida.
- Comunicaci√≥n bloqueante y no bloqueante.
- Gradiente conjugado con MPI.
- Particionamiento de dominios.
- Complemento de Schur.

### ‚öôÔ∏è Semana 16: Temas avanzados (opcionales)
- M√©todo alternante de Schwarz.
- Colorizaci√≥n de elementos.

---

## üß† Estrategias de ense√±anza-aprendizaje
- Aprendizaje activo y resoluci√≥n de problemas.
- Proyectos pr√°cticos de HPC.
- Simulaci√≥n y verificaci√≥n de resultados.
- Estudios de caso en f√≠sica computacional.
- Trabajo colaborativo en equipos.
- Uso de recursos en l√≠nea y documentaci√≥n t√©cnica.

---

## üìà Evaluaci√≥n
- Participaci√≥n y actividades pr√°cticas.
- Proyectos de pr√°ctica.
- Proyecto final.
- Informe t√©cnico y presentaci√≥n.

---

## üî¨ Pr√°cticas acad√©micas
Incluyen optimizaci√≥n de c√≥digo, paralelizaci√≥n con OpenMP y MPI, resoluci√≥n de sistemas de ecuaciones dispersas, an√°lisis de rendimiento y desarrollo de un modelo f√≠sico optimizado usando t√©cnicas de HPC.

---

## üìñ Bibliograf√≠a b√°sica
- Coulouris et al., *Distributed Systems ‚Äì Concepts and Design*
- Tanenbaum & Van Steen, *Distributed Systems*
- Gropp et al., *Using MPI*
- Pacheco, *An Introduction to Parallel Programming*
- Chapman et al., *Using OpenMP*
- Saad, *Iterative Methods for Sparse Linear Systems*

---

## üåê Recursos web
- OpenMP: https://www.openmp.org
- MPI Forum: https://www.mpi-forum.org
- Intel Optimization Manuals
- NVIDIA CUDA Documentation
